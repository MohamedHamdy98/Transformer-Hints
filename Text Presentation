Bag of Words
1- split all words [ i, hate, sharks, i, love, fishes ] without repeating
2- make all words have ID and count every word 
word I hate sharks love fishes
ID 1 2 3 4 5
D1 2 1 1 1 1
TF-IDF
التي اف بتقيس تكرار الكلمه في الدوكس, وال أي دي اف بتقيس تكراراو الكلمه دي مرتبطه بكام دوكس علي هي ظهرت فعلا في كام دوكس وارتباطها بكام دوكس بالفعل
لما بتعمل سيرش علي جوجل مثلا بكلام عشوائي او اي سيرش فازاي النتيجه بتطلع والسيرش دا بيحصل وازاي بتتبني العلاقات بين الجمل وبعضها عشان يديني نتايج متقاربه في الاخر من اللي بدور عليه؟
كمان محتاجين نعبر عن القيم اللي فوق بأرقام أكتر دقه وليها معني أكتر من كده وعشان الشبكه العصبيه تعرف تتعلم صح وتقدر تدي ويت لكل كلمه عن التانيه ومين أهم او اقرب للنتيجه الصح من مين وهنا دا دور الفانكشن دي.
Word 2 Vector (Word2Vec)
بتعبر عن كل كلمه مش بقيمه لأ انت هتعبر عنها بفيكتور عشان أقدر افهم معني اربتاط الكلام ببعضه والكوزاين سيميلاريتي بين الكلام وبعضه, زي مدي قرب كلمة مصر والقاهره ومدي بعد كلمة مصر والشاي, فبالتالي انت بتبني كلمات ليها معني وقيمه بإنك بتعبر عنها بفيكتور مش مجرد قيمه, فالكلامات اللي شبه بعض اتجمعت قرب بعض واللي مش شبه بعض اتفرقوا عن بعض
فبالتالي عن طريق انك مثلا تشوف ايه وجه الشبه بين ام كلثوم بالنسبه لراجل وامرأه فطبيعي هيجيب عبدالحليم لأنه أكتر حد شبها بس مش امرأه
بس انا كده حليت المشكله او قدرت اعبر واجيب المعني والتشابه الصح وكلام القريب لبعضه عن طريق كلمه, بس ممكن الكلامه تختلف باختلاف سياقها في الجمله , زي عيني تألمني ورأيت عين ما , فسياق الجمله بيخلي الكلمه تختلف معناها , ومن هنا بقي عايزين نحل المشكله دي
Encoder - Decoder

Summary
يبقي انت في الاول كنت بتعبر عن نصوص بأرقام ملهاش معني اوي او ملهاش معني أدق بعد كده بدأت تعبر عنها عن طريق انك تديها ويت عشوائي وتجسنها بالتدريب وتحسب التكرار ليها وكده , بس مازال برضو بتعبر برقم اه ادق شويه بس رقم , فظهرت انك تعبر عن الكلام بفيكتور وحلت المشكله دي وبقي الفيكتور بيجيبلك الكلام القريب من بعضه ويعبر بشكل دقيق جدا عن كل كلمه ومدي قربها من كلام تاني زيها , بس ظهرت مشكلة اختلاف معني الكلامه عن اختلاف سياق الجمله فبالتالي ظهرت الانكودر والديكودر
